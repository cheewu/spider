
2011-05-09 11:51:42+0800 [scrapy] INFO: Scrapy 0.12.0.2539 started (bot: zijiyou)
2011-05-09 11:51:44+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:44+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 11:51:44+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 11:51:44+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:44+0800 [scrapy] ERROR: 爬虫baseSeSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 11:51:44+0800 [scrapy] INFO: 启动爬虫：daodaoSpider
2011-05-09 11:51:44+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 11:51:44+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 11:51:44+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:44+0800 [scrapy] ERROR: 爬虫daodaoSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 11:51:44+0800 [scrapy] INFO: 启动爬虫：lvpingSpider
2011-05-09 11:51:44+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 11:51:44+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 11:51:44+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:44+0800 [scrapy] INFO: 开始crawl，第一个url : {u'status': 1000, u'reference': u'http://www.lvping.com/attractions-d152-guangzhou.html', u'url': u'http://www.lvping.com/attraction_review-d152-s6772-detail.html', u'dateTime': datetime.datetime(2011, 5, 8, 19, 1, 6, 950000), u'priority': 1000, u'callBack': None, u'spiderName': u'lvpingSpider', u'_id': ObjectId('4dc677f2834fc01e30000000')}
2011-05-09 11:51:44+0800 [scrapy] INFO: 爬虫lvpingSpider获得pendingRequest，数量=15
2011-05-09 11:51:44+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:45+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:45+0800 [scrapy] INFO: spider中间件开始从数据库加载CrawlUrl和ResponseBody.url，时间：2011-05-09 11:51:45.010789
2011-05-09 11:51:45+0800 [scrapy] INFO: 完成CrawlUrl加载，时间：2011-05-09 11:51:45.025923
2011-05-09 11:51:45+0800 [scrapy] INFO: 完成ResponseBody加载.从CrawlUrl加载20个；从ResponseBody加载0个；时间：2011-05-09 11:51:45.027685
2011-05-09 11:51:45+0800 [scrapy] INFO: spider中间件完成初始化urlDump. dump的长度=20；时间：2011-05-09 11:51:45.029251
2011-05-09 11:51:45+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:45+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 11:51:45+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 11:51:45+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 11:51:45+0800 [scrapy] INFO: 开始crawl，第一个url : {u'status': 1000, u'reference': u'http://www.lvping.com/attractions-d152-guangzhou.html', u'url': u'http://www.lvping.com/attraction_review-d152-s6772-detail.html', u'dateTime': datetime.datetime(2011, 5, 8, 19, 1, 6, 950000), u'priority': 1000, u'callBack': None, u'spiderName': u'lvpingSpider', u'_id': ObjectId('4dc677f2834fc01e30000000')}
2011-05-09 11:51:45+0800 [scrapy] INFO: 爬虫lvpingSpider获得pendingRequest，数量=15
2011-05-09 11:51:45+0800 [lvpingSpider] INFO: Spider opened
2011-05-09 11:51:45+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser：onSpiderOpen 
2011-05-09 11:51:47+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 11:51:47+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 11:51:47+0800 [scrapy] INFO: 从数据库查询的url开始crawl，len(pendingRequest)= 15
2011-05-09 11:51:47+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 11:51:47+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 普通页 url 数量：15
2011-05-09 11:51:47+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 Item页 url 数量：1
2011-05-09 11:51:47+0800 [scrapy] INFO: 保存item页，类型： Attraction
2011-05-09 11:51:47+0800 [scrapy] INFO: url总数量：17,排重数量：16，通过(添加到数据库)数量：1
2011-05-09 11:51:47+0800 [scrapy] INFO: ++++saveItem2Mongodb++++col:ResponseBody,objectId:4dc764d3834fc00bf7000000+++++++++++
2011-05-09 11:51:47+0800 [lvpingSpider] INFO: Passed None
2011-05-09 11:51:48+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 11:51:48+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 11:51:48+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 11:51:48+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html parse 产生 普通页 url 数量：0
2011-05-09 11:51:48+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html parse 产生 Item页 url 数量：0
2011-05-09 11:51:48+0800 [scrapy] INFO: 不是item的urlLink：http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 11:51:48+0800 [scrapy] INFO: 排重中间件所有的url均不重复！数量：0
2011-05-09 11:51:48+0800 [lvpingSpider] INFO: Closing spider (finished)
2011-05-09 11:51:48+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser:onSpiderClose 运行时间=3秒
2011-05-09 11:51:48+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-运行时间小于阀值。运行时间：3秒，间隔阀值：200秒
2011-05-09 11:51:48+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser信息：剩余待爬取的网页数量：15
2011-05-09 11:51:48+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-剩余待爬取的网页数量低于阀值：15
2011-05-09 11:51:48+0800 [scrapy] INFO: 开始清空数据库中的SeSpider中的搜索页列表，长度：0
2011-05-09 11:51:48+0800 [lvpingSpider] INFO: Spider closed (finished)
2011-05-09 12:00:39+0800 [scrapy] INFO: Scrapy 0.12.0.2539 started (bot: zijiyou)
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:00:39+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] ERROR: 爬虫baseSeSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:00:39+0800 [scrapy] INFO: 启动爬虫：daodaoSpider
2011-05-09 12:00:39+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:00:39+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] ERROR: 爬虫daodaoSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:00:39+0800 [scrapy] INFO: 启动爬虫：lvpingSpider
2011-05-09 12:00:39+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:00:39+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] ERROR: 爬虫lvpingSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] INFO: spider中间件开始从数据库加载CrawlUrl和ResponseBody.url，时间：2011-05-09 12:00:39.653997
2011-05-09 12:00:39+0800 [scrapy] INFO: 完成CrawlUrl加载，时间：2011-05-09 12:00:39.654721
2011-05-09 12:00:39+0800 [scrapy] INFO: 完成ResponseBody加载.从CrawlUrl加载0个；从ResponseBody加载0个；时间：2011-05-09 12:00:39.655309
2011-05-09 12:00:39+0800 [scrapy] INFO: spider中间件完成初始化urlDump. dump的长度=0；时间：2011-05-09 12:00:39.655470
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:00:39+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:00:39+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:00:39+0800 [scrapy] ERROR: 爬虫lvpingSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:00:39+0800 [lvpingSpider] INFO: Spider opened
2011-05-09 12:00:39+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser：onSpiderOpen 
2011-05-09 12:00:41+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:00:41+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:00:41+0800 [scrapy] INFO: 没有从数据库获得合适的url，将从stat_url开始crawl
2011-05-09 12:00:41+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:00:41+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 普通页 url 数量：0
2011-05-09 12:00:41+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 Item页 url 数量：1
2011-05-09 12:00:41+0800 [scrapy] INFO: 保存item页，类型： Attraction
2011-05-09 12:00:41+0800 [lvpingSpider] ERROR: Spider error processing <http://www.lvping.com/attraction_review-d1-s229-attraction.html> (referer: <None>)
	Traceback (most recent call last):
	  File "/usr/lib/python2.6/dist-packages/twisted/internet/base.py", line 1174, in mainLoop
	    self.runUntilCurrent()
	  File "/usr/lib/python2.6/dist-packages/twisted/internet/base.py", line 796, in runUntilCurrent
	    call.func(*call.args, **call.kw)
	  File "/usr/lib/python2.6/dist-packages/twisted/internet/defer.py", line 318, in callback
	    self._startRunCallbacks(result)
	  File "/usr/lib/python2.6/dist-packages/twisted/internet/defer.py", line 424, in _startRunCallbacks
	    self._runCallbacks()
	--- <exception caught here> ---
	  File "/usr/lib/python2.6/dist-packages/twisted/internet/defer.py", line 441, in _runCallbacks
	    self.result = callback(self.result, *args, **kw)
	  File "/usr/lib/pymodules/python2.6/scrapy/core/spidermw.py", line 61, in process_spider_output
	    result = method(response=response, result=result, spider=spider)
	  File "/home/shiym/workspace/zijiyou/zijiyou/zijiyou/middlewares/spidermid.py", line 46, in process_spider_output
	    for p in result:
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/spidermiddleware/referer.py", line 14, in <genexpr>
	    return (_set_referer(r) for r in result or ())
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/spidermiddleware/urllength.py", line 32, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/spidermiddleware/depth.py", line 48, in <genexpr>
	    return (r for r in result or () if _filter(r))
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib_exp/crawlspider/spider.py", line 57, in parse
	    output = iterate_spider_output(rule.callback(response))
	  File "/home/shiym/workspace/zijiyou/zijiyou/zijiyou/spiders/baseCrawlSpider.py", line 148, in baseParse
	    item = self.parseItem(response)
	  File "/home/shiym/workspace/zijiyou/zijiyou/zijiyou/spiders/baseCrawlSpider.py", line 179, in parseItem
	    loader.add_value('status', 100)
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/loader/__init__.py", line 38, in add_value
	    self._add_value(field_name, value)
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/loader/__init__.py", line 52, in _add_value
	    processed_value = self._process_input_value(field_name, value)
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/loader/__init__.py", line 102, in _process_input_value
	    proc = self.get_input_processor(field_name)
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/loader/__init__.py", line 91, in get_input_processor
	    self.default_input_processor)
	  File "/usr/lib/pymodules/python2.6/scrapy/contrib/loader/__init__.py", line 108, in _get_item_field_attr
	    value = self.item.fields[field_name].get(key, default)
	exceptions.KeyError: 'status'
	
2011-05-09 12:00:42+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:00:42+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:00:42+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:00:42+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html parse 产生 普通页 url 数量：0
2011-05-09 12:00:42+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html parse 产生 Item页 url 数量：0
2011-05-09 12:00:42+0800 [scrapy] INFO: 不是item的urlLink：http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:00:42+0800 [scrapy] INFO: 排重中间件所有的url均不重复！数量：0
2011-05-09 12:00:42+0800 [lvpingSpider] INFO: Closing spider (finished)
2011-05-09 12:00:42+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser:onSpiderClose 运行时间=3秒
2011-05-09 12:00:42+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-运行时间小于阀值。运行时间：3秒，间隔阀值：200秒
2011-05-09 12:00:42+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser信息：剩余待爬取的网页数量：0
2011-05-09 12:00:42+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-剩余待爬取的网页数量低于阀值：0
2011-05-09 12:00:42+0800 [scrapy] INFO: 开始清空数据库中的SeSpider中的搜索页列表，长度：0
2011-05-09 12:00:42+0800 [lvpingSpider] INFO: Spider closed (finished)
2011-05-09 12:04:17+0800 [scrapy] INFO: Scrapy 0.12.0.2539 started (bot: zijiyou)
2011-05-09 12:04:17+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:04:18+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] ERROR: 爬虫baseSeSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:04:18+0800 [scrapy] INFO: 启动爬虫：daodaoSpider
2011-05-09 12:04:18+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:04:18+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] ERROR: 爬虫daodaoSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:04:18+0800 [scrapy] INFO: 启动爬虫：lvpingSpider
2011-05-09 12:04:18+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:04:18+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] ERROR: 爬虫lvpingSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] INFO: spider中间件开始从数据库加载CrawlUrl和ResponseBody.url，时间：2011-05-09 12:04:18.400571
2011-05-09 12:04:18+0800 [scrapy] INFO: 完成CrawlUrl加载，时间：2011-05-09 12:04:18.402167
2011-05-09 12:04:18+0800 [scrapy] INFO: 完成ResponseBody加载.从CrawlUrl加载0个；从ResponseBody加载0个；时间：2011-05-09 12:04:18.403314
2011-05-09 12:04:18+0800 [scrapy] INFO: spider中间件完成初始化urlDump. dump的长度=0；时间：2011-05-09 12:04:18.403653
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:04:18+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:04:18+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:04:18+0800 [scrapy] ERROR: 爬虫lvpingSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:04:18+0800 [lvpingSpider] INFO: Spider opened
2011-05-09 12:04:18+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser：onSpiderOpen 
2011-05-09 12:04:20+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:04:20+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:04:20+0800 [scrapy] INFO: 没有从数据库获得合适的url，将从stat_url开始crawl
2011-05-09 12:04:20+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:04:20+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 普通页 url 数量：0
2011-05-09 12:04:20+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 Item页 url 数量：1
2011-05-09 12:04:20+0800 [scrapy] INFO: 保存item页，类型： Attraction
2011-05-09 12:04:20+0800 [scrapy] INFO: url总数量：2,排重数量：1，通过(添加到数据库)数量：1
2011-05-09 12:04:20+0800 [scrapy] INFO: ++++saveItem2Mongodb++++col:ResponseBody,objectId:4dc767c4834fc00d33000000+++++++++++
2011-05-09 12:04:20+0800 [lvpingSpider] INFO: Passed None
2011-05-09 12:04:21+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:04:21+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:04:21+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:04:21+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html parse 产生 普通页 url 数量：0
2011-05-09 12:04:21+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html parse 产生 Item页 url 数量：0
2011-05-09 12:04:21+0800 [scrapy] INFO: 不是item的urlLink：http://www.lvping.com/attraction_review-d308-s12565-ArcdeTriomphe.html
2011-05-09 12:04:21+0800 [scrapy] INFO: 排重中间件所有的url均不重复！数量：0
2011-05-09 12:04:21+0800 [lvpingSpider] INFO: Closing spider (finished)
2011-05-09 12:04:21+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser:onSpiderClose 运行时间=3秒
2011-05-09 12:04:21+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-运行时间小于阀值。运行时间：3秒，间隔阀值：200秒
2011-05-09 12:04:21+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser信息：剩余待爬取的网页数量：0
2011-05-09 12:04:21+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-剩余待爬取的网页数量低于阀值：0
2011-05-09 12:04:21+0800 [scrapy] INFO: 开始清空数据库中的SeSpider中的搜索页列表，长度：0
2011-05-09 12:04:21+0800 [lvpingSpider] INFO: Spider closed (finished)
2011-05-09 12:14:58+0800 [scrapy] INFO: Scrapy 0.12.0.2539 started (bot: zijiyou)
2011-05-09 12:14:59+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:14:59+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:14:59+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:14:59+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:14:59+0800 [scrapy] ERROR: 爬虫baseSeSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:14:59+0800 [scrapy] INFO: 启动爬虫：daodaoSpider
2011-05-09 12:14:59+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:14:59+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:14:59+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:14:59+0800 [scrapy] ERROR: 爬虫daodaoSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:14:59+0800 [scrapy] INFO: 启动爬虫：lvpingSpider
2011-05-09 12:14:59+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:14:59+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:14:59+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:14:59+0800 [scrapy] ERROR: 爬虫lvpingSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:15:00+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:15:00+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:15:00+0800 [scrapy] INFO: spider中间件开始从数据库加载CrawlUrl和ResponseBody.url，时间：2011-05-09 12:15:00.434010
2011-05-09 12:15:00+0800 [scrapy] INFO: 完成CrawlUrl加载，时间：2011-05-09 12:15:00.435807
2011-05-09 12:15:00+0800 [scrapy] INFO: 完成ResponseBody加载.从CrawlUrl加载0个；从ResponseBody加载0个；时间：2011-05-09 12:15:00.441306
2011-05-09 12:15:00+0800 [scrapy] INFO: spider中间件完成初始化urlDump. dump的长度=0；时间：2011-05-09 12:15:00.442148
2011-05-09 12:15:00+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:15:00+0800 [scrapy] INFO: 初始配置 initConfig
2011-05-09 12:15:00+0800 [scrapy] INFO: self.mongoApt为空，初始化mongod链接，并查询recentequest
2011-05-09 12:15:00+0800 [scrapy] INFO: ++初始化MongoDbApt++++++++++++++++++++++++++++++++++++
2011-05-09 12:15:00+0800 [scrapy] ERROR: 爬虫lvpingSpider 的pendingRequest为空，交由scrapy从startUrl启动
2011-05-09 12:15:00+0800 [lvpingSpider] INFO: Spider opened
2011-05-09 12:15:00+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser：onSpiderOpen 
2011-05-09 12:15:02+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:15:02+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:15:02+0800 [scrapy] INFO: 没有从数据库获得合适的url，将从stat_url开始crawl
2011-05-09 12:15:02+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d1-s229-attraction.html
2011-05-09 12:15:02+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 普通页 url 数量：0
2011-05-09 12:15:02+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d1-s229-attraction.html parse 产生 Item页 url 数量：1
2011-05-09 12:15:02+0800 [scrapy] INFO: 保存item页，类型： Attraction
2011-05-09 12:15:02+0800 [scrapy] INFO: url总数量：2,排重数量：1，通过(添加到数据库)数量：1
2011-05-09 12:15:02+0800 [scrapy] INFO: ++++saveItem2Mongodb++++col:ResponseBody,objectId:4dc76a46834fc00e22000000+++++++++++
2011-05-09 12:15:02+0800 [lvpingSpider] INFO: Passed None
2011-05-09 12:15:03+0800 [scrapy] INFO: recentRequests 更新数据库访问状态。 url:http://www.lvping.com/attraction_review-d308-s12565-detail.html
2011-05-09 12:15:03+0800 [scrapy] INFO: new url=http://www.lvping.com/attraction_review-d308-s12565-detail.html
2011-05-09 12:15:03+0800 [scrapy] INFO: 解析link: http://www.lvping.com/attraction_review-d308-s12565-detail.html
2011-05-09 12:15:03+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-detail.html parse 产生 普通页 url 数量：0
2011-05-09 12:15:03+0800 [scrapy] INFO: http://www.lvping.com/attraction_review-d308-s12565-detail.html parse 产生 Item页 url 数量：1
2011-05-09 12:15:03+0800 [scrapy] INFO: 保存item页，类型： Attraction
2011-05-09 12:15:03+0800 [scrapy] INFO: url总数量：2,排重数量：1，通过(添加到数据库)数量：1
2011-05-09 12:15:03+0800 [scrapy] INFO: ++++saveItem2Mongodb++++col:ResponseBody,objectId:4dc76a47834fc00e22000001+++++++++++
2011-05-09 12:15:03+0800 [lvpingSpider] INFO: Passed None
2011-05-09 12:15:03+0800 [lvpingSpider] INFO: Closing spider (finished)
2011-05-09 12:15:03+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser:onSpiderClose 运行时间=3秒
2011-05-09 12:15:03+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-运行时间小于阀值。运行时间：3秒，间隔阀值：200秒
2011-05-09 12:15:04+0800 [scrapy] INFO: 爬虫：lvpingSpider 扩展diagnoser信息：剩余待爬取的网页数量：0
2011-05-09 12:15:04+0800 [scrapy] ERROR: 爬虫：lvpingSpider 扩展diagnoser警告：错误-剩余待爬取的网页数量低于阀值：0
2011-05-09 12:15:04+0800 [scrapy] INFO: 开始清空数据库中的SeSpider中的搜索页列表，长度：0
2011-05-09 12:15:04+0800 [lvpingSpider] INFO: Spider closed (finished)
